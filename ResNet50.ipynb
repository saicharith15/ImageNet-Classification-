{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, merge, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical, plot_model \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import pandas as pd \n",
    "import re \n",
    "import time \n",
    "import itertools \n",
    "import seaborn as sns  \n",
    "import keras \n",
    "import datetime\n",
    "\n",
    "from numpy import expand_dims\n",
    "from keras import callbacks \n",
    "from keras import layers\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import backend as k \n",
    "from keras import regularizers  \n",
    "from keras.layers import Activation, add, Conv2D, Conv2DTranspose, Dense, Dropout, Flatten, Input, Lambda, MaxPooling2D, Reshape, ZeroPadding2D, AveragePooling2D \n",
    "from keras.layers.convolutional import UpSampling2D \n",
    "from keras.losses import binary_crossentropy \n",
    "from keras.models import Model, Sequential \n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.utils import to_categorical, plot_model \n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix \n",
    "from timeit import default_timer as timer\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical_devices------------- 1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"physical_devices-------------\", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 3\n",
    "CLASSES = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_path): # Read images and convert it into the uniform size (224x224x3)\n",
    "    img_start = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    return cv2.resize(img_start, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames= os.listdir ('./images')\n",
    "x_train = []\n",
    "y_train = []\n",
    "for folder in filenames: # Read the file name.\n",
    "    for image in os.listdir(f'./images/{folder}'):# Use folder as parameter.\n",
    "        img = read_image(f'./images/{folder}/{image}') # Read the files in each folder.\n",
    "        x_train.append(img) # Append them (the file and label) in exact same order.\n",
    "        y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(x_train, y_train)) # build the relationship between image and label\n",
    "random.shuffle(c) # shuffle\n",
    "a, b = zip(*c) # get image and label back (the order of rows is changed but the label is always attached to image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit([\"African elephant\", \"ant\", \"asparagus\", \"bridge\", \"computer keyboard\",\"cow\",\"dining table\",\"Ferris wheel\",\"flower\",\"French bulldog\",\"gas pump\",\"gorilla\",\"hula-hoop\",\"jelly bean\",\"jellyfish\",\"king penguin\",\"kiwi\",\"koala\",\"limousine\",\"monarch\",\"motorcycling\",\"rodent\",\"roller coaster\",\"seashore\",\"sea slug\",\"sewing machine\",\"skyscraper\",\"snail\",\"tiger\",\"wasp's nest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_label = np.copy(b)\n",
    "b_label = label_encoder.transform(b_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(a, b_label, train_size=0.8,test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = np.copy(X_train)\n",
    "training_label = np.copy(y_train)\n",
    "test_image = np.copy(X_test)\n",
    "test_label = np.copy(y_test)\n",
    "\n",
    "training_image = np.array(training_image)\n",
    "training_label = np.array(training_label)\n",
    "test_image = np.array(test_image)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_norm = cv2.normalize(training_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "testing_images_norm = cv2.normalize(test_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label_OneHot = to_categorical(training_label, 30)\n",
    "y_label_OneHot = to_categorical(test_label, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(training_images_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    F1, F2, F3 = filters\n",
    "    X_replica = X\n",
    "\n",
    "    conv_name = 'res' + str(stage) + block + '_branch'\n",
    "    bnorm_name = 'bnorm' + str(stage) + block + '_branch'\n",
    "\n",
    "    X = Conv2D(F1, (1,1), strides= (1,1), padding= 'valid', name = conv_name + '2a', kernel_initializer= glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis= 3, name = bnorm_name + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F2, (f,f), strides= (1,1), padding= 'same', name = conv_name + '2b', kernel_initializer= glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis= 3, name = bnorm_name + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F3, (1,1), strides= (1,1), padding= 'valid', name = conv_name + '2c', kernel_initializer= glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis= 3, name = bnorm_name + '2c')(X)\n",
    "\n",
    "    X = Add()([X, X_replica])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional_block\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    F1, F2, F3 = filters\n",
    "    X_replica = X\n",
    "\n",
    "    conv_name = 'res' + str(stage) + block + '_branch'\n",
    "    bnorm_name = 'bnorm' + str(stage) + block + '_branch'\n",
    "\n",
    "    X = Conv2D(F1, (1,1), strides= (s,s), name = conv_name + '2a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name= bnorm_name + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F2, (f,f), strides= (1,1), name = conv_name + '2b', padding= 'same', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name= bnorm_name + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F3, (1,1), strides= (1,1), name = conv_name + '2c', padding= 'valid', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name= bnorm_name + '2c')(X)\n",
    "\n",
    "    X_replica = Conv2D(F3, (1,1), strides= (s,s), name = conv_name + '1', padding='valid', kernel_initializer= glorot_uniform(seed = 0))(X_replica)\n",
    "    X_replica = BatchNormalization(axis = 3, name = bnorm_name + '1')(X_replica)\n",
    "\n",
    "    X = Add()([X, X_replica])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet model\n",
    "def ResNet50(input_shape= (224,224,3), classes=30):\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D(padding= (3,3))(X_input)\n",
    "\n",
    "    #stage 1\n",
    "    X = Conv2D(64, (7,7), strides= (2,2), name= 'conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name= 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3,3), strides= (2,2))(X)\n",
    "\n",
    "    #stage 2\n",
    "    X = convolutional_block(X, f=3, filters= [64,64,256], stage=2, block= 'a', s=1)\n",
    "    X = identity_block(X, f=3, filters= [64,64,256], stage=2, block='b')\n",
    "    X = identity_block(X, f=3, filters= [64,64,256], stage=2, block='c')\n",
    "\n",
    "    #stage 3\n",
    "    X = convolutional_block(X, f=3, filters= [128,128,512], stage=3, block= 'a', s=2)\n",
    "    X = identity_block(X, f=3, filters= [128,128,512], stage=3, block='b')\n",
    "    X = identity_block(X, f=3, filters= [128,128,512], stage=3, block='c')\n",
    "    X = identity_block(X, f=3, filters= [128,128,512], stage=3, block='d')\n",
    "\n",
    "    #stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage=4, block='a', s = 2)\n",
    "    X = identity_block(X, f= 3, filters= [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, f= 3, filters= [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, f= 3, filters= [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, f= 3, filters= [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, f= 3, filters= [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    #stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage=5, block='a', s = 2)\n",
    "    X = identity_block(X, f= 3, filters= [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, f= 3, filters= [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    X = AveragePooling2D()(X)\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation= 'softmax', name='fc' + str(classes), kernel_initializer= glorot_uniform(seed= 0))(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2a_branch2a (BatchNormaliz (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 55, 55, 64)   0           bnorm2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2a_branch2b (BatchNormaliz (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           bnorm2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2a_branch2c (BatchNormaliz (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2a_branch1 (BatchNormaliza (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 256)  0           bnorm2a_branch2c[0][0]           \n",
      "                                                                 bnorm2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2b_branch2a (BatchNormaliz (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 64)   0           bnorm2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2b_branch2b (BatchNormaliz (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           bnorm2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2b_branch2c (BatchNormaliz (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           bnorm2b_branch2c[0][0]           \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2c_branch2a (BatchNormaliz (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 64)   0           bnorm2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2c_branch2b (BatchNormaliz (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           bnorm2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm2c_branch2c (BatchNormaliz (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           bnorm2c_branch2c[0][0]           \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3a_branch2a (BatchNormaliz (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           bnorm3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3a_branch2b (BatchNormaliz (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bnorm3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3a_branch2c (BatchNormaliz (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3a_branch1 (BatchNormaliza (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           bnorm3a_branch2c[0][0]           \n",
      "                                                                 bnorm3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3b_branch2a (BatchNormaliz (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           bnorm3b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3b_branch2b (BatchNormaliz (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bnorm3b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3b_branch2c (BatchNormaliz (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bnorm3b_branch2c[0][0]           \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3c_branch2a (BatchNormaliz (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           bnorm3c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3c_branch2b (BatchNormaliz (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bnorm3c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3c_branch2c (BatchNormaliz (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bnorm3c_branch2c[0][0]           \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3d_branch2a (BatchNormaliz (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           bnorm3d_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3d_branch2b (BatchNormaliz (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bnorm3d_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm3d_branch2c (BatchNormaliz (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bnorm3d_branch2c[0][0]           \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4a_branch2a (BatchNormaliz (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           bnorm4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4a_branch2b (BatchNormaliz (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bnorm4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4a_branch2c (BatchNormaliz (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4a_branch1 (BatchNormaliza (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           bnorm4a_branch2c[0][0]           \n",
      "                                                                 bnorm4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4b_branch2a (BatchNormaliz (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           bnorm4b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4b_branch2b (BatchNormaliz (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bnorm4b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4b_branch2c (BatchNormaliz (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bnorm4b_branch2c[0][0]           \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4c_branch2a (BatchNormaliz (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           bnorm4c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4c_branch2b (BatchNormaliz (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bnorm4c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4c_branch2c (BatchNormaliz (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bnorm4c_branch2c[0][0]           \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4d_branch2a (BatchNormaliz (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           bnorm4d_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4d_branch2b (BatchNormaliz (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bnorm4d_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4d_branch2c (BatchNormaliz (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bnorm4d_branch2c[0][0]           \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4e_branch2a (BatchNormaliz (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           bnorm4e_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4e_branch2b (BatchNormaliz (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bnorm4e_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4e_branch2c (BatchNormaliz (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bnorm4e_branch2c[0][0]           \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4f_branch2a (BatchNormaliz (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           bnorm4f_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4f_branch2b (BatchNormaliz (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bnorm4f_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm4f_branch2c (BatchNormaliz (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bnorm4f_branch2c[0][0]           \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5a_branch2a (BatchNormaliz (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           bnorm5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5a_branch2b (BatchNormaliz (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bnorm5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5a_branch2c (BatchNormaliz (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5a_branch1 (BatchNormaliza (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           bnorm5a_branch2c[0][0]           \n",
      "                                                                 bnorm5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5b_branch2a (BatchNormaliz (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           bnorm5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5b_branch2b (BatchNormaliz (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bnorm5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5b_branch2c (BatchNormaliz (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bnorm5b_branch2c[0][0]           \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5c_branch2a (BatchNormaliz (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           bnorm5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5c_branch2b (BatchNormaliz (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bnorm5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bnorm5c_branch2c (BatchNormaliz (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bnorm5c_branch2c[0][0]           \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 3, 3, 2048)   0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 18432)        0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fc30 (Dense)                    (None, 30)           552990      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,140,702\n",
      "Trainable params: 24,087,582\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/750 [..............................] - ETA: 1:03 - loss: 22.5256 - accuracy: 0.0156 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0626s vs `on_train_batch_end` time: 0.1068s). Check your callbacks.\n",
      "750/750 [==============================] - 142s 190ms/step - loss: 3.6444 - accuracy: 0.1892 - val_loss: 2.3998 - val_accuracy: 0.3113\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 139s 186ms/step - loss: 2.2465 - accuracy: 0.3512 - val_loss: 2.1279 - val_accuracy: 0.3875\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 141s 187ms/step - loss: 1.9559 - accuracy: 0.4340 - val_loss: 1.9493 - val_accuracy: 0.4418\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 143s 190ms/step - loss: 1.7526 - accuracy: 0.4888 - val_loss: 1.8544 - val_accuracy: 0.4637\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 143s 191ms/step - loss: 1.5644 - accuracy: 0.5372 - val_loss: 2.0409 - val_accuracy: 0.4323\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 1.3867 - accuracy: 0.5877 - val_loss: 1.6536 - val_accuracy: 0.5320\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 1.2322 - accuracy: 0.6306 - val_loss: 1.6610 - val_accuracy: 0.5290\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 1.0739 - accuracy: 0.6763 - val_loss: 1.6590 - val_accuracy: 0.5412\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 145s 193ms/step - loss: 0.9123 - accuracy: 0.7223 - val_loss: 1.5565 - val_accuracy: 0.5648\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 144s 191ms/step - loss: 0.7797 - accuracy: 0.7581 - val_loss: 1.8397 - val_accuracy: 0.5113\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 140s 187ms/step - loss: 0.6240 - accuracy: 0.8037 - val_loss: 1.8439 - val_accuracy: 0.5320\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 140s 186ms/step - loss: 0.4905 - accuracy: 0.8457 - val_loss: 1.6839 - val_accuracy: 0.5817\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 142s 190ms/step - loss: 0.3630 - accuracy: 0.8845 - val_loss: 1.9052 - val_accuracy: 0.5632\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 140s 187ms/step - loss: 0.2832 - accuracy: 0.9103 - val_loss: 1.9011 - val_accuracy: 0.5762\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 140s 186ms/step - loss: 0.2201 - accuracy: 0.9291 - val_loss: 2.0395 - val_accuracy: 0.5572\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 144s 193ms/step - loss: 0.1633 - accuracy: 0.9483 - val_loss: 2.3900 - val_accuracy: 0.5317\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 0.1344 - accuracy: 0.9578 - val_loss: 2.1544 - val_accuracy: 0.5808\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 143s 191ms/step - loss: 0.0972 - accuracy: 0.9703 - val_loss: 2.0694 - val_accuracy: 0.5968\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 144s 193ms/step - loss: 0.0739 - accuracy: 0.9776 - val_loss: 2.1427 - val_accuracy: 0.6062\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 139s 186ms/step - loss: 0.0717 - accuracy: 0.9792 - val_loss: 2.3195 - val_accuracy: 0.5782\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 143s 191ms/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 3.1000 - val_accuracy: 0.5155\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 142s 190ms/step - loss: 0.0408 - accuracy: 0.9884 - val_loss: 2.1338 - val_accuracy: 0.6073\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 143s 191ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 2.2583 - val_accuracy: 0.6083\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 2.1204 - val_accuracy: 0.6122\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 2.3586 - val_accuracy: 0.5913\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 2.4330 - val_accuracy: 0.5883\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 140s 187ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 2.2916 - val_accuracy: 0.6162\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 143s 190ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 2.5593 - val_accuracy: 0.5872\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 2.2480 - val_accuracy: 0.6147\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 2.3952 - val_accuracy: 0.6098\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 2.4209 - val_accuracy: 0.5920\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 143s 190ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 2.2925 - val_accuracy: 0.6145\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 141s 189ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 2.3442 - val_accuracy: 0.6142\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 145s 193ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 2.4399 - val_accuracy: 0.6055\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 143s 190ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 2.4132 - val_accuracy: 0.6117\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 2.4031 - val_accuracy: 0.6158\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 145s 194ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 2.4160 - val_accuracy: 0.6075\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 138s 184ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 2.5759 - val_accuracy: 0.6005\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 2.4166 - val_accuracy: 0.6137\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 138s 184ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 2.3778 - val_accuracy: 0.6158\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 138s 184ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 2.4265 - val_accuracy: 0.6113\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 138s 184ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 2.5448 - val_accuracy: 0.5985\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 145s 193ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 2.8942 - val_accuracy: 0.5837\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 139s 186ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 2.7157 - val_accuracy: 0.5890\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 147s 196ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 2.5585 - val_accuracy: 0.5953\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 147s 196ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 2.5597 - val_accuracy: 0.5992\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 2.5247 - val_accuracy: 0.6132\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 2.4135 - val_accuracy: 0.6175\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 143s 190ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 2.4275 - val_accuracy: 0.6130\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 145s 194ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 2.4192 - val_accuracy: 0.6240\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 141s 189ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 2.4060 - val_accuracy: 0.6220\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 2.4404 - val_accuracy: 0.6177\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 2.4958 - val_accuracy: 0.6130\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 2.4230 - val_accuracy: 0.6237\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 2.4083 - val_accuracy: 0.6253\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 2.4196 - val_accuracy: 0.6228\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 147s 196ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 2.4377 - val_accuracy: 0.6208\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 145s 193ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 2.4189 - val_accuracy: 0.6238\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 2.4435 - val_accuracy: 0.6212\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 2.4520 - val_accuracy: 0.6208\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 142s 190ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 2.5916 - val_accuracy: 0.6158\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 2.5257 - val_accuracy: 0.6132\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 142s 190ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.4479 - val_accuracy: 0.6220\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 140s 186ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 2.6282 - val_accuracy: 0.6043\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 140s 186ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 2.4420 - val_accuracy: 0.6232\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 146s 195ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 2.4301 - val_accuracy: 0.6183\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 144s 192ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 2.4639 - val_accuracy: 0.6213\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 140s 187ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 2.4810 - val_accuracy: 0.6215\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 138s 184ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 2.4207 - val_accuracy: 0.6272\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 140s 187ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 2.4482 - val_accuracy: 0.6273\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 2.4496 - val_accuracy: 0.6210\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 139s 186ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 2.4664 - val_accuracy: 0.6220\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 2.4769 - val_accuracy: 0.6192\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 141s 188ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 2.4593 - val_accuracy: 0.6165\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 2.4415 - val_accuracy: 0.6168\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 143s 190ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 2.5166 - val_accuracy: 0.6113\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 142s 190ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 2.5244 - val_accuracy: 0.6213\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 140s 187ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 2.5295 - val_accuracy: 0.6207\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.4592 - val_accuracy: 0.6267\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 2.5035 - val_accuracy: 0.6203\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 2.5372 - val_accuracy: 0.6183\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 2.5214 - val_accuracy: 0.6213\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 2.4820 - val_accuracy: 0.6307\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 2.4866 - val_accuracy: 0.6295\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 2.5464 - val_accuracy: 0.6180\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 2.4778 - val_accuracy: 0.6233\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 141s 189ms/step - loss: 8.0942e-04 - accuracy: 0.9999 - val_loss: 2.4614 - val_accuracy: 0.6287\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 2.4585 - val_accuracy: 0.6318\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 7.9358e-04 - accuracy: 0.9999 - val_loss: 2.6250 - val_accuracy: 0.6162\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 142s 189ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 2.4840 - val_accuracy: 0.6248\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 140s 187ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 2.4697 - val_accuracy: 0.6332\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 2.5091 - val_accuracy: 0.6292\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 2.4930 - val_accuracy: 0.6287\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.4669 - val_accuracy: 0.6233\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 2.5113 - val_accuracy: 0.6268\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.4947 - val_accuracy: 0.6305\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.5205 - val_accuracy: 0.6303\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 139s 185ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.6809 - val_accuracy: 0.6148\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 8.9979e-04 - accuracy: 0.9998 - val_loss: 2.5007 - val_accuracy: 0.6295\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 138s 185ms/step - loss: 5.3707e-04 - accuracy: 1.0000 - val_loss: 2.4976 - val_accuracy: 0.6288\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_images_norm, x_label_OneHot, batch_size=32, epochs=100,\n",
    "                     validation_data=(testing_images_norm, y_label_OneHot), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
